# 4.1 算法移植概述

​**对于基于深度学习的视频/图片分析任务来说，通常都包括如下几个步骤：**

1. 视频/图片解码
2. 输入预处理
3. 模型推理
4. 输出后处理
5. 视频/图片编码

实际任务中，算法往往还会包含多个不同神经网络模型，因此，步骤2-4会根据需要反复执行多次。

**硬件加速支持情况**

实践证明，单纯针对神经网络运算进行加速，已经无法满足真实场景的需求。为了提高算法运行效率，BM168X中除张量运算硬件加速单元TPU外，还集成了针对编解码、图像处理等操作的若干硬件加速模块，用户通过SophonSDK中提供的相应的软件接口库，可以对如上几个步骤进行针对性地加速，从而便捷地开发出高效的算法和应用。

为了满足客户对不同风格接口使用的偏好，我们还对硬件加速接口库进行了多次封装，用户可以自行选取合适的接口库进行开发，具体情况总结如下：

| **任务流程** | **是否支持硬件加速** | **SAIL高级接口库** | **OPENCV接口库** | **FFMPEG接口库** | **Native接口库** |
| -------- | ------------ | ------------- | ------------- | ------------- | ------------- |
| 视频/图片解码  | 支持           | sail::Decoder | Y             | Y             | BMCV(图片)      |
| 输入预处理    | 支持           | sail::Bmcv    | Y             | N             | BMCV          |
| 模型推理     | 支持           | sail::Engine  | N             | N             | BMruntime     |
| 输出后处理    | 部分支持         | sail::Bmcv    | N             | N             | BMCV          |
| 视频/图片编码  | 支持           | sail::Bmcv    | Y             | Y             | BMCV(图片)      |

值得一提的是，为了提高算法效率以及硬件特性的要求，用户在调用硬件加速接口的时候需要注意以下几个方面，后续的文档会通过实例来进行具体阐述：

​ 1. 内存零copy

​ 2. 申请物理连续内存

​ 3. 将多个预处理步骤进行合并

​ 4. 凑4batch进行推理

#### **C/C++/Python三种编程接口**

目前提供了C/C++/Python三种编程接口的支持：BMRuntime、 BMCV、 BMLib三个模块提供给了C接口编程；Python/C++接口是基于SAIL库实现的。

SAIL（Sophon Artificial Intelligent Library），是对 SophonSDK中的 BMRuntime、 BMCV、 BMLib等底层库的高级封装，将 SDK中原有的“加载 BModel 并驱动 TPU 推理”、“驱动 TPU 做图像处理”、“驱动 VPU 做图像和视频解码”等功能抽象成更为简单的 C++ 接口对外提供；并且使用 pybind11 再次封装，提供了简洁易用的Python接口。目前， SAIL 模块中所有的类、枚举、函数都在“sail”名字空间下， 关于SAILC++/Python 接口详细内容请阅读 [《SAIL用户开发手册》](https://doc.sophgo.com/docs/3.0.0/docs\_latest\_release/sophon-inference/html/index.html)。
